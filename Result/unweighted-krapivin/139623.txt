which|WDT|BODY_12:BODY_15:BODY_13:BODY_2:BODY_3:BODY_4:BODY_6:BODY_5:ABSTRACT_8:BODY_1:BODY_10:BODY_7:BODY_8:BODY_9|0
it|PRP|ABSTRACT_18:BODY_18:BODY_13:BODY_2:BODY_14:BODY_3:BODY_4:BODY_6:BODY_5:BODY_1:ABSTRACT_1:BODY_10:BODY_7:BODY_9|0
this|DT|BODY_12:BODY_13:BODY_2:BODY_1:BODY_3:BODY_10:BODY_4:BODY_7:BODY_8|0
sutton|NN|BODY_12:BODY_6:BODY_5:BODY_2:BODY_1:BODY_3:BODY_4:BODY_7:BODY_8:BODY_9|0
there|EX|BODY_5:BODY_13:BODY_2:BODY_1:BODY_3:BODY_4:BODY_19:BODY_10:BODY_7|0
the chain|DT NN|BODY_12:BODY_5:BODY_11:BODY_15:BODY_1:BODY_3:BODY_4:BODY_7:BODY_9|0
that|WDT|BODY_6:BODY_5:BODY_11:BODY_18:BODY_2:BODY_14:BODY_3:BODY_4:BODY_7:BODY_8:BODY_9|0
watkins|NNS|BODY_12:BODY_11:ABSTRACT_2:BODY_1:BODY_2:ABSTRACT_3:BODY_3:BODY_4|0
the case|DT NN|BODY_6:BODY_11:BODY_17:BODY_13:BODY_1:BODY_3:BODY_4:ABSTRACT_7:BODY_7|0
each state|DT NN|BODY_6:BODY_11:BODY_5:BODY_13:BODY_4:BODY_7:BODY_8:BODY_9|0
equation|NN|BODY_5:BODY_2:BODY_3:BODY_7:BODY_8|0
1|CD|BODY_6:BODY_5:BODY_27:BODY_1:BODY_2:BODY_3:BODY_4:BODY_10|0
a|DT|BODY_5:BODY_28:BODY_19:BODY_10:BODY_7:BODY_8|0
q|RB|BODY_5:BODY_15:BODY_1:BODY_2:BODY_3:BODY_7:BODY_8|0
td(-)|NN|BODY_5:BODY_11:BODY_16:BODY_15:BODY_2|0
i|SYM|BODY_6:BODY_5:BODY_16:BODY_17:BODY_8:BODY_9|0
n|NN|BODY_6:BODY_13:BODY_2:BODY_3:BODY_10:BODY_4:BODY_8|0
the states|DT NNS|BODY_6:BODY_11:BODY_5:BODY_1:BODY_2:BODY_3:BODY_8|0
vn|NN|BODY_11:BODY_1:BODY_2:BODY_3:BODY_10:BODY_7:BODY_8:BODY_9|0
a )|DT -RRB-|BODY_6:BODY_11:BODY_5:BODY_3:BODY_7|0
the predictions|DT NNS|BODY_2:BODY_3:BODY_4:BODY_7:BODY_9|0
probability one|NN CD|BODY_12:BODY_5:ABSTRACT_6:BODY_17:BODY_13:BODY_4:BODY_7:BODY_8:BODY_9|0
states|NNS|BODY_5:BODY_3:BODY_4:BODY_7:BODY_8|0
one|CD|BODY_12:BODY_5:BODY_2:BODY_4:BODY_8|0
state|NN|BODY_6:BODY_5:BODY_16:BODY_14:BODY_10:BODY_4:BODY_19:BODY_7:BODY_8|0
r|NN|BODY_6:BODY_5:BODY_2:BODY_1:BODY_4:BODY_8|0
the value|DT NN|BODY_5:BODY_1:BODY_2:BODY_3:BODY_4:BODY_8|0
the estimates|DT NNS|BODY_6:BODY_1:BODY_3:BODY_7:BODY_9|0
td(0 )|NN -RRB-|BODY_5:BODY_10:BODY_4:BODY_9|0
state i|NN NN|BODY_12:BODY_3:BODY_7:BODY_8:BODY_9|0
they|PRP|BODY_13:BODY_1:BODY_3:BODY_4|0
he|PRP|BODY_5:BODY_1:BODY_2:BODY_7|0
the sequence|DT NN|BODY_11:BODY_5:BODY_14:BODY_9|0
terms|NNS|BODY_5:BODY_2:BODY_3:BODY_4|0
z|FW|BODY_11:BODY_4:BODY_10|0
an absorbing markov chain|DT VBG NN NN|BODY_12:BODY_11:BODY_5:BODY_1:BODY_3:BODY_4:BODY_10|0
theorem t|NN NN|BODY_5:BODY_2:BODY_14:BODY_3|0
the conditions|DT NNS|BODY_6:BODY_1:BODY_2:BODY_9|0
the expected values|DT VBN NNS|BODY_6:BODY_5:BODY_2:BODY_3|0
the weights|DT NNS|BODY_5:BODY_3:BODY_4:BODY_7|0
the terminal value|DT NN NN|BODY_3:BODY_10:BODY_8:BODY_9|0
one state|CD NN|BODY_6:BODY_11:BODY_8|0
( i|-LRB- FW|BODY_6:BODY_5:BODY_3:BODY_7|0
the equivalent|DT NN|BODY_13:BODY_1:BODY_3:BODY_4|0
what|WP|BODY_11:BODY_5:BODY_2:BODY_4|0
the markov chain|DT NN NN|BODY_2:BODY_7:BODY_8:BODY_9|0
the linear representation|DT NN NN|BODY_5:BODY_19:BODY_4|0
i 0|NN CD|BODY_5:BODY_2:BODY_4:BODY_9|0
the error|DT NN|BODY_5:BODY_2:BODY_7|0
q-learning|NN|BODY_5:BODY_11:BODY_1:BODY_2:BODY_8|0
td|NN|BODY_5:BODY_2:BODY_3:BODY_7|0
converges|NNS|BODY_3:BODY_4:BODY_8:BODY_9|0
the mean|DT NN|BODY_12:BODY_5:BODY_14:BODY_10|0
i vn|FW NN|BODY_5:BODY_2:BODY_3:BODY_4|0
all|DT|BODY_5:BODY_21:BODY_2:BODY_1:BODY_3|0
e|NN|BODY_12:BODY_2:BODY_1:BODY_3:BODY_10|0
the transitions|DT NNS|BODY_6:BODY_4:BODY_7|0
v|FW|BODY_3:BODY_10:BODY_7:BODY_8|0
such|JJ|BODY_4:BODY_9|0
the prediction|DT NN|BODY_6:BODY_5:BODY_7|0
the expected number|DT VBN NN|BODY_6:BODY_4|0
ff|NN|BODY_5:BODY_23:BODY_7|0
figure|NN|BODY_6:BODY_16:BODY_2:BODY_7|0
the system|DT NN|BODY_2:BODY_4|0
[17]|NNP|BODY_5:BODY_16:BODY_2|0
x|NN|BODY_1:BODY_2:BODY_3:BODY_10:BODY_20|0
the previous section|DT JJ NN|BODY_6:BODY_5:BODY_18:BODY_10|0
random variables|JJ NNS|BODY_2:BODY_3|0
the proof|DT NN|BODY_1:BODY_2:BODY_3|0
's theorem|POS NN|BODY_5:BODY_3:BODY_10:BODY_4:BODY_7|0
barto , sutton and watkins|NN , NN CC NNS|BODY_6:BODY_11:BODY_2|0
full rank|JJ NN|BODY_11:BODY_2:BODY_3|0
sutton [17]|NN NN|BODY_6:BODY_1:BODY_3|0
convergence|NN|ABSTRACT_8:BODY_3|0
j|NN|BODY_5:BODY_14|0
them|PRP|BODY_11:BODY_5:BODY_17:BODY_1:BODY_2|0
equation ( 10 )|NN -LRB- CD -RRB-|BODY_17:BODY_2:BODY_3|0
these predictions|DT NNS|BODY_2:BODY_3|0
a and g|DT CC NN|BODY_21:BODY_2|0
the sum|DT NN|BODY_1:BODY_4|0
temporal differences|JJ NNS|ABSTRACT_2:BODY_2|0
i \gamma ffx t|NN NN NN NN|BODY_5:BODY_25|0
e !1|NN NNS|BODY_2|0
the utility|DT NN|BODY_2|0
the observed sequence|DT JJ NN|BODY_3:BODY_7:BODY_8|0
a special case|DT JJ NN|BODY_6:BODY_2|0
state j|NN NN|BODY_11:BODY_2|0
[19]|NN|BODY_2|0
observation vectors|NN NNS|BODY_16:BODY_3|0
the q|DT NN|BODY_2:BODY_7|0
both sides|DT NNS|BODY_6:BODY_11|0
the context|DT NN|BODY_16:BODY_3|0
0|CD|BODY_3:BODY_7:BODY_8|0
times|NNS|BODY_6:BODY_3:BODY_10:BODY_7|0
this result|DT NN|BODY_2:BODY_1:BODY_3|0
the v r|DT NN NN|BODY_1:BODY_3:BODY_7|0
every state|DT NN|BODY_6:BODY_12:BODY_18|0
the convergence|DT NN|TITLE_1:BODY_2:BODY_3|0
dynamic programming|JJ NN|BODY_5:BODY_8|0
a particular case|DT JJ NN|BODY_6:BODY_4|0
3 )|CD -RRB-|BODY_6:BODY_2|0
td( 1 )|NN CD -RRB-|BODY_6:BODY_2|0
terminal value|NN NN|BODY_6:BODY_10|0
absorption|NN|BODY_6:BODY_5|0
sequences|NNS|BODY_6:BODY_2|0
8i 2 n|NN CD NN|BODY_5:BODY_9|0
a set|DT NN|BODY_2|0
an eigenvector|DT NN|BODY_2:BODY_3|0
these|DT|BODY_2:BODY_1|0
the x i|DT NN NN|BODY_2:BODY_9|0
a full set|DT JJ NN|BODY_6:BODY_3:BODY_19|0
the values|DT NNS|BODY_2:BODY_19|0
the matrix|DT NN|BODY_21:BODY_2:BODY_3|0
an example|DT NN|BODY_2|0
the numbers|DT NNS|BODY_6:BODY_3|0
c|NN|BODY_4:BODY_9|0
( i 0|-LRB- FW CD|BODY_4:BODY_9|0
the chain absorbs|DT NN NNS|BODY_17:BODY_3|0
's proof|POS NN|BODY_2:BODY_3:BODY_8|0
each|DT|BODY_6:BODY_7|0
the expected value|DT JJ NN|BODY_2:BODY_7|0
the number|DT NN|BODY_5:BODY_2:BODY_9|0
the v|DT NNS|BODY_2:BODY_4|0
ab|JJ|BODY_6:BODY_16|0
the transition matrix|DT NN NN|BODY_1:BODY_3:BODY_9|0
this manner|DT NN|BODY_5:BODY_7|0
r steps|NN NNS|BODY_4:BODY_8|0
( i t+1 vn|-LRB- IN CD IN|BODY_12:BODY_2|0
' analysis|POS NN|BODY_3:BODY_4|0
the behaviour|DT NN|BODY_5:BODY_8|0
b|NN|BODY_5:BODY_3|0
this paper|DT NN|BODY_2:BODY_1:ABSTRACT_1|0
temporal difference methods|JJ NN NNS|BODY_3|0
the earliest work|DT JJS NN|BODY_2|0
the mean contraction properties|DT JJ NN NNS|BODY_3|0
the previous subsection|DT JJ NN|BODY_2|0
the same|DT JJ|BODY_2|0
the td(-) algorithm|DT JJ NN|BODY_3|0
the td(-) weight change formula|DT JJ NN NN NN|BODY_3|0
these variables|DT NNS|BODY_2|0
dp|NN|BODY_5:BODY_4|0
the one|DT CD|BODY_5|0
td methods|JJ NNS|BODY_3:BODY_7|0
the weight vector|DT NN NN|BODY_6:BODY_14|0
an observed sequence|DT JJ NN|BODY_2:BODY_10|0
' '|POS POS|BODY_3|0
a procedure|DT NN|BODY_9|0
this sum|DT NN|BODY_19|0
17 )|CD -RRB-|BODY_2|0
kd-trees|NNS|BODY_2|0
draughts ) playing program|NNS -RRB- VBG NN|BODY_2|0
x i|SYM FW|BODY_5:BODY_23|0
the right hand barrier|DT JJ NN NN|BODY_12:BODY_5|0
6 )|CD -RRB-|BODY_18:BODY_3|0
the estimate|DT NN|BODY_12:BODY_9|0
the intermediate predictions|DT JJ NNS|BODY_2|0
one way|CD NN|ABSTRACT_4:BODY_1|0
the representation|DT NN|BODY_5:BODY_4|0
( i t|-LRB- FW NN|BODY_13:BODY_3|0
the ideal predictions|DT JJ NNS|BODY_4:BODY_9|0
7]|NNP|BODY_2|0
their desired values|PRP$ VBN NNS|BODY_5:BODY_4|0
the on-line version|DT JJ NN|BODY_4|0
28 )|CD -RRB-|BODY_10:BODY_4|0
i )|FW -RRB-|BODY_6:BODY_3:BODY_4|0
a way|DT NN|BODY_5:BODY_8|0
(|-LRB-|BODY_3:BODY_7|0
w r|RB VBD|BODY_19:BODY_10|0
viz convergence|NN NN|BODY_16:BODY_13|0
lim|PRP|BODY_6:BODY_16|0
non-absorbing|JJ|BODY_2|0
linear td(-)|NN NN|BODY_2|0
the expected weights|DT VBN NNS|BODY_21|0
different representations|JJ NNS|BODY_2|0
their temporal distance|PRP$ JJ NN|BODY_5:BODY_15|0
count|NN|BODY_7|0
expected values|VBN NNS|BODY_15:BODY_1|0
all positive ff|DT JJ NN|BODY_2|0
those numbers|DT NNS|BODY_10|0
20|CD|BODY_2|0
the delta-rule|DT NN|BODY_2|0
( 12|-LRB- CD|BODY_2|0
the inequality|DT NN|BODY_2|0
one sequence|CD NN|BODY_10:BODY_4:BODY_7|0
a further related paper|DT JJ VBN NN|BODY_6|0
d and|JJ CC|BODY_2|0
the amount|DT NN|BODY_1:BODY_3|0
the second|DT JJ|BODY_1:BODY_9|0
s|PRP|BODY_4:BODY_9|0
possible actions|JJ NNS|BODY_7|0
the expected value e[zji]|DT VBN NN NNS|BODY_4|0
6= 0,|JJ NN|BODY_4:BODY_8|0
17]|CD|BODY_6|0
the punctate representation|DT NN NN|BODY_2|0
eigenvalues|NNS|BODY_4:BODY_7:BODY_20|0
dp [4|NN NNS|BODY_2|0
some policy -(i|DT NN NN|BODY_2|0
state i and action|NN NN CC NN|BODY_2|0
these terminating values|DT NN VBZ|BODY_10|0
the less significant|DT JJR JJ|BODY_2|0
i)|JJ|BODY_11:BODY_4|0
just the probability|RB DT NN|BODY_4|0
some future outcome|DT JJ NN|BODY_2|0
the effect|DT NN|BODY_14|0
)|-RRB-|TITLE_3|0
the probabilities|DT NNS|BODY_5:BODY_7|0
equation ( 26 )|NN -LRB- CD -RRB-|BODY_5:BODY_9|0
q ) values|VBN -RRB- NNS|BODY_4|0
' theorem|POS NN|ABSTRACT_3:BODY_3:BODY_4|0
a look-up table|DT NN NN|BODY_2|0
a complete sequence|DT JJ NN|BODY_10|0
the transition probabilities|DT NN NNS|BODY_12:BODY_5|0
observations|NNS|BODY_11:BODY_2|0
the terms|DT NNS|BODY_2|0
/|NN|BODY_1:BODY_10|0
higher values|JJR NNS|BODY_4|0
's bucket brigade method|POS NN NN NN|BODY_7|0
@|LS|BODY_17|0
2 n|CD NN|BODY_6:BODY_16|0
the next|DT JJ|BODY_10:BODY_9|0
action|NN|BODY_6:BODY_7|0
this case|DT NN|BODY_1|0
y|NN|BODY_5:BODY_3:BODY_8|0
x t|NN NN|BODY_4|0
a and component i|DT CC NN NN|BODY_18|0
any eigenvalue-eigenvector pair|DT JJS NN|BODY_2|0
the entire proof|DT JJ NN|BODY_2|0
the vector representation|DT NN NN|BODY_6:BODY_8|0
the v r random variables|DT NN NN JJ NNS|BODY_5:BODY_16|0
the appendix|DT NN|BODY_2:BODY_3|0
[13]|NN|BODY_3|0
a review ) or cmacs|DT NN -RRB- CC NNS|BODY_4|0
actions|NNS|BODY_6:BODY_8:BODY_9|0
classifier systems|NN NNS|BODY_8|0
the rule|DT NN|BODY_8|0
a consistent function|DT JJ NN|BODY_3|0
average|NN|BODY_6:BODY_8|0
all eigenvalues|DT NNS|BODY_1:BODY_24|0
both strictly positive|DT RB JJ|BODY_8|0
the effects|DT NNS|BODY_5:BODY_7|0
board positions|NN NNS|BODY_4|0
positive real parts|JJ JJ NNS|BODY_8|0
the real part|DT JJ NN|BODY_9|0
consistent predictions|JJ NNS|ABSTRACT_5|0
the|DT|BODY_3|0
( xv ) xv|-LRB- NN -RRB- NN|BODY_7|0
another theorem|DT NN|BODY_1|0
bias and variance|NN CC NN|BODY_2|0
combines prediction and control|NNS NN CC NN|BODY_2|0
different|JJ|BODY_2|0
dynamic programming ( dp )|JJ NN -LRB- NN -RRB-|BODY_1|0
the non-discounted case|DT JJ NN|BODY_1|0
the trade-off|DT NN|BODY_1|0
varga [18] lim|NN NN NN|BODY_2|0
each step|DT NN|BODY_16|0
q r|NN NN|BODY_5:BODY_4|0
the right side (|DT JJ NN -LRB-|BODY_5|0
successive vectors|JJ NNS|BODY_3|0
arbitrary ones.it|JJ NN|ABSTRACT_12|0
td behaves|JJ NNS|ABSTRACT_14|0
t|IN|BODY_11:BODY_20|0
positive definiteness|JJ NN|BODY_6|0
complete sequences|JJ NNS|BODY_2|0
that i|DT NN|BODY_3|0
this version|DT NN|ABSTRACT_13|0
this point|DT NN|BODY_2|0
that x t xd|DT NN NN NN|BODY_2|0
whose effect|WP$ NN|BODY_5|0
markov chains|NN NNS|BODY_3|0
the terminal nodes|DT NN NNS|BODY_7|0
a problem|DT NN|BODY_5|0
all non|DT FW|BODY_3|0
sharing|VBG|BODY_4|0
the observed terminal value|DT JJ JJ NN|BODY_11:BODY_5|0
the simplest|DT JJS|BODY_3|0
learning|NN|BODY_11:BODY_1:BODY_10:BODY_8|0
no longer|DT RBR|BODY_3|0
just sutton|RB NN|BODY_4|0
the sums|DT NNS|BODY_15|0
a prediction|DT NN|BODY_3|0
modulus|NN|BODY_28:BODY_4|0
just some particular set|RB DT JJ NN|BODY_19|0
these terminal values|DT JJ NNS|BODY_3|0
empirical results|JJ NNS|BODY_3|0
ways|NNS|BODY_5|0
the subsequently predicted values|DT RB VBN NNS|BODY_9|0
any outcome distributions|DT NN NNS|BODY_12|0
klopf [9 , 10]|NN CD , CD|BODY_5|0
[17] discusses holland|JJ NNS CC|BODY_6|0
watkins [19]|NNS NNS|BODY_1|0
xv|NN|BODY_3|0
the derivative , ie|DT JJ , NN|BODY_3|0
faster learning|JJR VBG|BODY_5|0
notation|NN|BODY_4|0
a b|DT NN|BODY_4|0
the transition|DT NN|BODY_9|0
that involving information|DT VBG NN|ABSTRACT_11|0
a b)g|DT NN|BODY_10|0
the more significant|DT JJR JJ|BODY_2|0
equation ( 16 )|NN -LRB- CD -RRB-|BODY_7|0
e[w r n n|JJ NN NN NN|BODY_13|0
the face|DT NN|ABSTRACT_15|0
a quite similar navigation task|DT RB JJ NN NN|BODY_4|0
adjacent time steps|JJ NN NNS|ABSTRACT_10|0
an|DT|BODY_1:BODY_8|0
p|NN|BODY_13:BODY_1|0
whether td(-)|IN JJ|BODY_3|0
their values|PRP$ NNS|BODY_4|0
22 )|CD -RRB-|BODY_11|0
g|NN|BODY_14|0
linearly dependent representations|RB JJ NNS|ABSTRACT_16|0
theorem|NN|BODY_3:BODY_7|0
weight updates|NN NNS|BODY_6|0
each sequence ) converge|DT NN -RRB- NN|BODY_7|0
the predictors|DT NNS|BODY_9|0
the algorithm|DT NN|BODY_5:BODY_8|0
the problem|DT NN|BODY_6:BODY_1|0
the correct predictions|DT JJ NNS|BODY_6:BODY_1|0
any starting values|DT VBG NNS|BODY_5|0
the discrepancy|DT NN|BODY_5|0
the members|DT NNS|BODY_2|0
the exponentially weighted sum|DT RB JJ NN|BODY_2|0
d(|NN|BODY_2|0
( 31 )|-LRB- CD -RRB-|BODY_9|0
augmenting td(-)|JJ NN|BODY_2|0
@ e e e e|JJ NN NN NN NN|BODY_3|0
backwards|NNS|BODY_9|0
dynamic programming ( dp ) [4 ]|JJ NN -LRB- NN -RRB- CD NN|BODY_2|0
just the loaded square error|RB DT JJ NN NN|BODY_2|0
temporal difference|JJ NN|BODY_6|0
the convergence theorem|DT NN NN|BODY_2|0
then the truth|RB DT NN|BODY_2|0
non-terminal states vectors|JJ VBZ NNS|BODY_8|0
e io h e e|NN NN NN NN NN|BODY_20|0
whose contribution|WP$ NN|BODY_11|0
their 'shared|PRP$ JJ|BODY_6|0
some comments|DT NNS|BODY_8|0
matrix form|NN NN|BODY_2|0
equation ( 24|NN -LRB- CD|BODY_2|0
the left hand one|DT JJ NN CD|BODY_6:BODY_15|0
ik q kj|NN NN NN|BODY_4|0
a learning rule|DT NN NN|BODY_4|0
the qualities|DT NNS|BODY_9|0
the first strong proof|DT JJ JJ NN|BODY_6|0
the contributions|DT NNS|BODY_3|0
un (|FW -LRB-|BODY_8|0
a and|DT CC|BODY_26|0
a different solution|DT JJ NN|BODY_5|0
statistically better estimators|RB JJR NNS|BODY_7|0
any state|DT NN|BODY_3|0
this change|DT NN|BODY_13|0
td(myampersandlambda|NN|TITLE_2|0
the linear case|DT NN NN|BODY_7|0
the two statistical processes|DT CD JJ NNS|BODY_4|0
the vectors|DT NNS|BODY_2:BODY_10|0
the interaction|DT NN|BODY_3|0
the square error|DT JJ NN|BODY_2|0
expected value|VBN NN|BODY_8|0
a linear combination|DT NN NN|BODY_12|0
its convergence|PRP$ NN|BODY_6|0
the absorbing ones|DT JJ NNS|BODY_4|0
( i 1|-LRB- FW CD|BODY_2|0
its estimate|PRP$ NN|BODY_12:BODY_17|0
the 'bootstraps|DT NNS|BODY_13|0
the current state x|DT JJ NN SYM|BODY_10|0
each complete observation sequence|DT JJ NN NN|BODY_4|0
sutton [16|NN NNS|BODY_5|0
the components|DT NNS|BODY_14|0
a sequence|DT NN|BODY_1:BODY_9|0
discounted future values|VBN NN NNS|BODY_10|0
the unhelpful correlations|DT JJ NNS|BODY_3|0
's main td(-) equation|POS JJ JJ NN|BODY_5|0
the linear one|DT NN NN|BODY_4|0
-.|VBG|BODY_15:BODY_10|0
punctate or distributed representations|NN CC VBN NNS|BODY_4|0
the equations|DT NNS|BODY_2|0
- e|: NN|BODY_5|0
the square matrix|DT NN NN|BODY_13|0
( i ff [vn|-LRB- IN NN NN|BODY_11|0
varga [18]|NN NN|BODY_3|0
the learning rule|DT NN NN|BODY_4|0
the limit|DT NN|BODY_5|0
entry|NN|BODY_8|0
the underlying td(-) algorithm|DT VBG NN NN|BODY_4|0
equations|NNS|BODY_10|0
( 30|-LRB- CD|BODY_8|0
this equation|DT NN|BODY_6|0
any vector u|DT NN NN|BODY_12|0
since therefore|IN RB|BODY_3|0
using|VBG|BODY_14|0
ffi ab|JJ JJ|BODY_29|0
better generalisation|JJR NN|BODY_6|0
the equivalents|DT NNS|BODY_15|0
' value|POS NN|BODY_3|0
reward|NN|BODY_11|0
no two states|DT CD NNS|BODY_10|0
lms|NNS|BODY_3|0
v r|FW NN|BODY_1:BODY_3|0
adjacent states|JJ NNS|BODY_10|0
( 2|-LRB- CD|BODY_2|0
if|IN|BODY_6|0
similar lines|JJ NNS|BODY_2|0
any initial weight vector|DT JJ NN NN|BODY_3|0
all the elements|PDT DT NNS|BODY_2|0
t terminal|NN NN|BODY_7|0
the states b|DT NNS NN|BODY_3|0
powers|NNS|BODY_14|0
ab = [x|JJ SYM JJ|BODY_25|0
two issues|CD NNS|BODY_3|0
rwn v|RB FW|BODY_3|0
another way|DT NN|BODY_2|0
higher variance|JJR NN|BODY_2|0
smaller variance|JJR NN|BODY_2|0
h|NN|BODY_6|0
vn ( i 0 ) rwn vn|JJ -LRB- FW CD -RRB- NN JJ|BODY_3|0
common|JJ|BODY_8|0
watkins'|NNS|BODY_7|0
limited depth games-tree searches|JJ NN NN NNS|BODY_8|0
e e|NN NN|BODY_6|0
the dependence|DT NN|BODY_12|0
an early td system|DT JJ NN NN|BODY_2|0
an immediate reward|DT JJ NN|BODY_2|0
ie one|NN CD|BODY_2|0
its elemental pieces|PRP$ JJ NNS|BODY_2|0
temporally extended circumstances|RB VBN NNS|BODY_2|0
the w|DT NN|BODY_7|0
this problem|DT NN|BODY_2|0
an activity trace|DT NN NN|BODY_3|0
any distribution|DT NN|BODY_7|0
all the eigenvalues 1 \gamma ff/|DT DT NNS CD NN NN|BODY_2|0
[x|JJ|BODY_24|0
td ) estimation|NN -RRB- NN|BODY_7|0
little alteration|JJ NN|BODY_2|0
non-terminal states|JJ VBZ|BODY_9|0
an upended pole|DT JJ NN|BODY_4|0
singular|JJ|BODY_4|0
the frequency|DT NN|BODY_5|0
the unbiased terminal values|DT JJ NN NNS|BODY_7|0
sense|NN|BODY_4|0
e and e[zji 0|NN CC NN CD|BODY_3|0
the next state x|DT JJ NN SYM|BODY_7|0
( 21 )|-LRB- CD -RRB-|BODY_3|0
a non-zero probability|DT JJ NN|BODY_2|0
td estimators|DT NNS|BODY_4|0
the variance|DT NN|BODY_9|0
the current prediction function vn|DT JJ NN NN NN|BODY_2|0
f|NN|BODY_11:BODY_13|0
1 )|CD -RRB-|BODY_3|0
linear td(-) (|JJ NN -LRB-|BODY_5|0
all r|DT NN|BODY_4|0
a basis|DT NN|BODY_2:BODY_1|0
a convergence theorem|DT NN NN|ABSTRACT_5|0
the crucial condition|DT JJ NN|BODY_9|0
the terminal values|DT NN NNS|BODY_15|0
a close relation|DT JJ NN|BODY_16|0
the possible transitions|DT JJ NNS|BODY_6|0
50 % probability|CD NN NN|BODY_8|0
a different answer|DT JJ NN|ABSTRACT_19|0
appropriate ff defining|JJ NN NN|BODY_2|0
the left absorbing barrier|DT VBN NN NN|BODY_6|0
the reduction|DT NN|BODY_3|0
td )|NN -RRB-|ABSTRACT_3|0
the iteration matrix|DT NN NN|BODY_3|0
certain different representations|JJ JJ NNS|BODY_10|0
the definition|DT NN|BODY_7|0
term|NN|BODY_8|0
learning rates|NN NNS|BODY_3|0
x t xd|NN NN NN|BODY_5|0
a fruitful way|DT JJ NN|BODY_3|0
every non-terminal state|DT JJ NN|BODY_2|0
all the eigenvalues|PDT DT NNS|BODY_4|0
values|NNS|BODY_5|0
expectations|NNS|BODY_10|0
anexample|NN|BODY_5|0
one entry|CD NN|BODY_3|0
absorbing markov chains|JJ NN NNS|BODY_17|0
a separate convergence proof|DT JJ NN NN|BODY_8|0
the random moves|DT JJ NNS|BODY_5|0
vn+1 ( i 0 vn|NN -LRB- IN CD IN|BODY_10|0
the terminal|DT NN|BODY_20|0
any linearly independent set|DT JJ JJ NN|BODY_15|0
this procedure|DT NN|BODY_2|0
probabilities|NNS|BODY_8|0
( i )|-LRB- FW -RRB-|BODY_8|0
a whole collection|DT JJ NN|BODY_6|0
equation (|NN -LRB-|BODY_17|0
2 a|CD DT|BODY_3|0
a policy|DT NN|BODY_3|0
a under policy|DT JJ NN|BODY_3|0
some further random processes|DT JJ JJ NNS|BODY_9|0
' proof|POS NN|BODY_13|0
werbos|NNS|BODY_1|0
the mean weight|DT JJ NN|BODY_5|0
i 2 n ik q kj|NN CD NN NN NN NN|BODY_3|0
the v(|DT NN|BODY_3|0
the predicted values|DT VBN NNS|BODY_6|0
the relationship|DT NN|BODY_5|0
the ab|DT JJ|BODY_7|0
that x|IN NN|BODY_10|0
( i m and vn+1|-LRB- IN NN CC NN|BODY_7|0
obey standard stochastic convergence criteria|JJ JJ JJ NN NNS|BODY_4|0
the influence|DT NN|BODY_4|0
forwards|NNS|BODY_10|0
a finite set|DT JJ NN|BODY_6|0
important , weighted exponentially less|JJ , JJ RB RBR|BODY_14|0
iterations|NNS|BODY_2|0
the a th component|DT DT IN NN|BODY_11|0
the vector|DT NN|BODY_17|0
a potentially stochastic relationship|DT RB JJ NN|BODY_3|0
finite expected values|JJ VBN NNS|BODY_13|0
re re ( /( xv|NN NN -LRB- JJ NN|BODY_2|0
any absorbing markov chain|DT JJ NN NN|BODY_6|0
the method|DT NN|BODY_1:ABSTRACT_1|0
the arrows|DT NNS|BODY_4|0
the time|DT NN|BODY_12|0
the wn|DT NN|BODY_5|0
the diagonal ab|DT JJ JJ|BODY_27|0
td)|NN|BODY_3|0
equation e e e|NN NN NN NN|BODY_14|0
sutton used p n|NN VBN NN NN|BODY_3|0
the derivative|DT JJ|BODY_6|0
the existence|DT NN|BODY_4|0
a second issue|DT JJ NN|BODY_2|0
the s-step transition|DT NN NN|BODY_4|0
'completing|VBG|BODY_2|0
information|NN|ABSTRACT_9|0
the fact|DT NN|BODY_7|0
components|NNS|BODY_14|0
the possibility|DT NN|BODY_13|0
sets and values|NNS CC NNS|BODY_6|0
the new estimator|DT JJ NN|BODY_8|0
any intermediate states|DT JJ NNS|BODY_5|0
d i|JJ NN|BODY_5|0
each absorbing state|DT JJ NN|BODY_6|0
one assumption|CD NN|BODY_8|0
the gradient descent|DT JJ NN|BODY_4|0
the training values|DT NN NNS|BODY_3|0
their exact analogues|PRP$ JJ NNS|BODY_3|0
splitting|NN|BODY_12|0
incremental dynamic programming|JJ JJ NN|BODY_7|0
addition|NN|BODY_3|0
0 ( i|CD -LRB- FW|BODY_6|0
27 )|CD -RRB-|BODY_4|0
the target values|DT NN NNS|BODY_8|0
26-28|CD|BODY_15|0
the difference|DT NN|BODY_2|0
( 23 )|-LRB- CD -RRB-|BODY_12|0
:|:|BODY_4|0
29 )|CD -RRB-|BODY_6|0
a collection|DT NN|BODY_5|0
recency|NN|BODY_9|0
the proof breaks|DT NN NNS|BODY_4|0
24 )|CD -RRB-|BODY_8|0
r 2 n|NN CD NN|BODY_9|0
this technique|DT NN|BODY_2|0
the question|DT NN|BODY_2|0
the new prediction weight vector|DT JJ NN NN NN|BODY_8|0
the training sequences|DT NN NNS|BODY_6|0
rewards|NNS|BODY_14|0
the outcomes|DT NNS|BODY_4|0
this section|DT NN|BODY_1|0
a degenerate case|DT JJ NN|BODY_7|0
each component|DT NN|BODY_6|0
15 )|CD -RRB-|BODY_9|0
the extra terms|DT JJ NNS|BODY_12|0
a fixed learning rate ff|DT VBN NN NN NN|BODY_6|0
a superscript|DT NN|BODY_6|0
lim @ e|JJ NN NN|BODY_5|0
a stochastic transition|DT JJ NN|BODY_9|0
both i|DT NN|BODY_7|0
a markov matrix p ij|DT NN NN NN NN|BODY_10|0
whose distribution|WP$ NN|BODY_6|0
statesdemonstrating|NN|ABSTRACT_17|0
degenerate|NN|BODY_17|0
arbitrary states|JJ NNS|BODY_13|0
stochastic convergence|JJ NN|BODY_12|0
r\gammastep moves|NN NNS|BODY_6|0
a consequence|DT NN|BODY_5|0
eigenvalue 0|DT CD|BODY_4|0
account|NN|BODY_4|0
the observation|DT NN|BODY_9|0
13 )|CD -RRB-|BODY_3|0
the k|DT NN|BODY_6|0
the following theorem|DT VBG NN|BODY_4|0
any matrix m|DT NN NN|BODY_9|0
\cal q-learning|JJ NN|ABSTRACT_4|0
the loading factors|DT NN NNS|BODY_6|0
just the normal lms estimator [21]|RB DT JJ NNS NN NN|BODY_3|0
wn|JJ|BODY_5|0
p 1|VB CD|BODY_10|0
some results|DT NNS|BODY_2|0
the ( similarly defined ) u|DT -LRB- RB VBN -RRB- FW|BODY_4|0
the strategy|DT NN|BODY_4|0
probability one sutton|NN CD NN|BODY_7|0
the nadir|DT NN|BODY_11|0
its relationship|PRP$ NN|BODY_4|0
prediction|NN|BODY_4|0
that td(0 )|DT NN -RRB-|BODY_5|0
all other stochastic convergence proofs|DT JJ JJ NN NNS|BODY_9|0
the simple random walkshown|DT JJ JJ NN|BODY_6|0
some lim|DT NN|BODY_5|0
the look-up table|DT NN NN|BODY_7|0
no further|DT RB|BODY_3|0
pages|NNS|BODY_14|0
's treatment|POS NN|BODY_6|0
a td(-based estimator|DT JJ NN|BODY_7|0
whose components|WP$ NNS|BODY_18|0
i t+1 vn|FW CD NN|BODY_12|0
the sense|DT NN|BODY_18|0
one special case|CD JJ NN|BODY_4|0
one particular sequence|CD JJ NN|BODY_8|0
the watkins construction|DT NNS NN|BODY_15|0
general for|JJ IN|BODY_2|0
these successive estimates|DT JJ NNS|BODY_3|0
2 )|CD -RRB-|BODY_10|0
the whole point|DT JJ NN|BODY_8|0
2.4 linear representation|CD NN NN|BODY_1|0
[14 , 15]|CD , CD|BODY_4|0
contraction properties|NN NNS|BODY_1|0
equation ( 4 )|NN -LRB- CD -RRB-|BODY_4|0
some|DT|BODY_1|0
the overall td(-) estimator|DT JJ JJ NN|BODY_4|0
the representation sutton|DT NN NN|BODY_4|0
these expressions|DT NNS|BODY_1|0
state j probabilities|NN NN NNS|BODY_11|0
the full linear case|DT JJ NN NN|BODY_2|0
exactly the same and|RB DT JJ CC|BODY_6|0
equation ( 25 )|NN -LRB- CD -RRB-|BODY_6|0
t+1 :w|DT NN|BODY_8|0
markov pro- cesses|NN NNS NNS|BODY_4|0
the lms rule|DT NNS NN|BODY_5|0
prediction and action learning|NN CC NN NN|BODY_6|0
the rewards|DT NNS|BODY_4|0
absorbs|NNS|BODY_5|0
vn wn :x|JJ JJ NN|BODY_4|0
the entry|DT NN|BODY_6|0
error reduction|NN NN|BODY_5:BODY_1|0
the temporal order|DT JJ NN|BODY_4|0
fl|NN|BODY_13|0
just the terminal value|RB DT NN NN|BODY_4|0
's proof procedure|POS NN NN|BODY_9|0
the rationale|DT NN|BODY_2|0
strict inequality|JJ NN|BODY_3|0
the action|DT NN|BODY_6|0
the ultimate proof|DT JJ NN|BODY_2|0
time|NN|BODY_7|0
the key step|DT JJ NN|BODY_6|0
stage n|NN NN|BODY_7|0
the estimated terminal values|DT VBN NN NNS|BODY_10|0
a time horizon|DT NN NN|BODY_7|0
the expected ultimate terminal|DT VBN JJ NN|BODY_5|0
the on-line form|DT JJ NN|BODY_9|0
' terms|POS NNS|BODY_2|0
the equation|DT NN|BODY_7|0
equation ( 9 )|NN -LRB- CD -RRB-|BODY_4|0
the discount factor|DT NN NN|BODY_14:BODY_3|0
ff z|NN FW|BODY_7|0
the inconsistency|DT NN|BODY_6|0
the less the effect|DT JJR DT NN|BODY_6|0
the more effect|DT JJR NN|BODY_6|0
a weighted average|DT JJ NN|BODY_3|0
an observation|DT NN|BODY_4|0
each place|DT NN|BODY_8|0
a form|DT NN|BODY_5|0
the proofs|DT NNS|BODY_9|0
the bias|DT NN|BODY_6|0
a simultaneous equation|DT JJ NN|BODY_7|0
no more|DT RBR|BODY_7|0
the supervised least mean squares|DT JJ JJS JJ NNS|BODY_2|0
point|NN|BODY_4|0
only one step|JJ CD NN|BODY_8|0
the parameters|DT NNS|BODY_5|0
a lemma|DT NN|BODY_2|0
equation ( 5 )|NN -LRB- CD -RRB-|BODY_3|0
z j|FW NN|BODY_8|0
n sequences|NN NNS|BODY_15|0
vectors x i|NNS NN NN|BODY_3|0
judging and hence improving policies|VBG CC RB VBG NNS|BODY_6|0
a learning technique|DT NN NN|BODY_3|0
the expected terminal values|DT VBN NN NNS|BODY_4|0
random chance|JJ NN|BODY_5|0
future states|JJ NNS|BODY_4|0
( i r|-LRB- NN NN|BODY_4|0
no inaccessible states|DT JJ NNS|BODY_11|0
as least as good as|RB RBS RB JJ RB|BODY_5|0
the first state|DT JJ NN|BODY_6|0
only the next state|RB DT JJ NN|BODY_8|0
the lms case|DT NNS NN|BODY_9|0
the maximum|DT NN|BODY_2|0
whose real parts|WP$ JJ NNS|BODY_6:BODY_22|0
stage|NN|BODY_10:BODY_9|0
any x i|DT NN NN|BODY_15|0
[21] technique|CD NN|BODY_4|0
e and so xd e|NN CC RB JJ NN|BODY_2|0
only one action|RB CD NN|BODY_11|0
[|PRP|BODY_5|0
6=|NN|BODY_3|0
the current weight vector|DT JJ NN NN|BODY_9|0
equal probabilities|JJ NNS|BODY_3|0
equation ( 2|NN -LRB- CD|BODY_2|0
1989|CD|ABSTRACT_4|0
all the possible options|PDT DT JJ NNS|BODY_5|0
2 about|CD IN|BODY_2|0
controlled|VBN|BODY_3|0
inconsistencies|NNS|BODY_9|0
the general case|DT JJ NN|BODY_11|0
these differences|DT NNS|BODY_2|0
z otherwise ( 5 )|FW RB -LRB- CD -RRB-|BODY_5|0
0 such|CD JJ|BODY_1|0
all the estimates|PDT DT NNS|BODY_3|0
the q values|DT NN NNS|BODY_3|0
this fact|DT NN|BODY_1|0
the strongest guarantee|DT JJS NN|BODY_7|0
a slightly different case|DT RB JJ NN|BODY_6|0
all those states|PDT DT NNS|BODY_5|0
probability|NN|BODY_10|0
sutton ( 1988 )|NN -LRB- CD -RRB-|ABSTRACT_6|0
td prediction|VBD NN|BODY_7|0
a degree|DT NN|BODY_4|0
ole|NN|BODY_11|0
some i|DT NN|BODY_4|0
a localist state representation|DT JJ NN NN|BODY_11|0
that td(0|IN NN|BODY_10|0
a state|DT NN|BODY_3|0
whose columns|WP$ NNS|BODY_22|0
interpolating|NN|BODY_6|0
e and f|NN CC NN|BODY_5|0
the inaccurate estimates|DT JJ NNS|BODY_6|0
the observed terminal value z|DT JJ NN NN NN|BODY_10|0
here the raw information|RB DT JJ NN|BODY_3|0
the characteristic functions|DT JJ NNS|BODY_4|0
the expected frequencies|DT JJ NNS|BODY_7|0
ie mapping|NN NN|BODY_7|0
the 'best|DT JJS|BODY_2|0
qn ( i|NN -LRB- FW|BODY_2|0
first learning|JJ NN|BODY_3|0
a controlled markov process|DT JJ NN NN|BODY_8|0
i \gamma|NN NN|BODY_26|0
each policy|DT NN|BODY_6|0
equation ( 27 )|NN -LRB- CD -RRB-|BODY_8|0
the distribution|DT NN|BODY_10|0
inequality|NN|BODY_4|0
tr2t|NN|BODY_5|0
the task|DT NN|BODY_4|0
the next ,|DT JJ ,|BODY_13|0
his closely related prediction and action learning method|PRP$ RB VBN NN CC NN VBG NN|ABSTRACT_5|0
either the estimate vn|RB DT NN NN|BODY_3|0
no requirement|DT NN|BODY_4|0
terminal locations|JJ NNS|BODY_8|0
defining v|VBG FW|BODY_9|0
its obeisance|PRP$ NN|BODY_3|0
his method|PRP$ NN|BODY_6|0
no knowledge|DT NN|BODY_11|0
matrix x|NN NN|BODY_2|0
more sequences|JJR NNS|BODY_5|0
a trade|DT NN|BODY_5|0
a random variable r i|DT JJ JJ NN NN|BODY_4|0
its value|PRP$ NN|BODY_2|0
the important r|DT JJ NN|BODY_10|0
' convergence theorem|POS NN NN|BODY_5|0
one version|CD NN|BODY_6|0
rwn vn|JJ NN|BODY_5|0
an exact parallel|DT JJ NN|BODY_7|0
state d|NN NN|BODY_2|0
the td(-) rule|DT JJ NN|BODY_5|0
d( i \gamma q )|JJ NN NN NN -RRB-|BODY_17|0
this formula|DT NN|BODY_9|0
any|DT|BODY_7|0
the matrix 3 convergence|DT NN CD NN|BODY_6|0
the prediction function v|DT NN NN FW|BODY_3|0
the random walk|DT JJ NN|BODY_9|0
i r|FW NN|BODY_2|0
mutatis mutandis|NN NNS|BODY_6|0
the world|DT NN|BODY_11|0
the ever increasing probability|DT RB VBG NN|BODY_5|0
differs|NNS|BODY_4|0
this strong form|DT JJ NN|ABSTRACT_7|0
some analysis|DT NN|ABSTRACT_2|0
the discounted predictive version|DT VBN JJ NN|BODY_3|0
insert|NN|BODY_1|0
each visit|DT NN|BODY_12|0
the part|DT NN|BODY_2|0
no relation|DT NN|BODY_6|0
td(0 ) prediction converges|DT -RRB- NN NNS|BODY_11|0
i 1 vn ( i 2 defining vn|FW CD NN -LRB- FW CD VBG NN|BODY_6|0
the wherewithal|DT JJ|BODY_4|0
the payoff structure|DT NN NN|BODY_14|0
g(|NN|BODY_4|0
themselves|PRP|BODY_8|0
every non-absorbing state|DT JJ NN|BODY_4|0
future values|JJ NNS|BODY_10|0
the zenith|DT NN|BODY_15|0
the changes|DT NNS|BODY_8|0
's result|POS NN|BODY_3|0
functions|NNS|BODY_4|0
those|DT|BODY_4|0
visits|NNS|BODY_5|0
general symmetric|JJ JJ|BODY_2|0
an absorbing markov process|DT JJ NN NN|BODY_7|0
these terms|DT NNS|BODY_3|0
vn+1 ( i 0 vn (|RB -LRB- FW CD NN -LRB-|BODY_3|0
the update rule|DT NN NN|BODY_11|0
' insights|POS NNS|BODY_3|0
' representation-free proof|POS JJ NN|BODY_4|0
( 18|-LRB- CD|BODY_9|0
one set|CD NN|BODY_6|0
his checkers|PRP$ NNS|BODY_1|0
more sophisticated representations|RBR JJ NNS|BODY_1|0
the conjugate transpose|DT NN NN|BODY_4|0
time t|NN NN|BODY_20|0
witten [22]|JJ NN|BODY_10|0
a markov chain|DT NN NN|BODY_4|0
the non-terminal states|DT JJ NNS|BODY_10|0
a valid estimator|DT JJ NN|BODY_2|0
the learning phase|DT NN NN|BODY_1|0
a method|DT NN|BODY_2|0
0,|CD|BODY_1|0
source and destination states|NN CC NN NNS|BODY_5|0
an optimal policy|DT JJ NN|BODY_4|0
reasonably 1=2|RB CD|BODY_6|0
multiplying equation|JJ NN|BODY_1|0
the particular sequence|DT JJ NN|BODY_4|0
correlations|NNS|BODY_4|0
no diagonal elements|DT JJ NNS|BODY_5|0
a ( weak )|DT -LRB- JJ -RRB-|BODY_6|0
all the weights|DT DT NNS|BODY_3|0
( i summing|-LRB- FW NN|BODY_4|0
the new representation|DT JJ NN|BODY_1|0
easier|JJR|BODY_8|0
extra bias|JJ NN|BODY_2|0
michie and chambers|NN CC NNS|BODY_7|0
t x|NN SYM|BODY_1|0
14 )|CD -RRB-|BODY_3|0
a number|DT NN|BODY_1|0
the q-learning theorem|DT NN NN|BODY_1|0
the change|DT NN|BODY_8|0
that state|DT NN|BODY_5|0
the normal running|DT JJ NN|BODY_14|0
a non-absorbing chain|DT JJ NN|BODY_12|0
a version|DT NN|BODY_3|0
the probability|DT NN|BODY_3|0
various differences|JJ NNS|BODY_3|0
that sequence|DT NN|BODY_11|0
the dependency|DT NN|BODY_3|0
just one component|RB CD NN|BODY_5|0
at least one optimal policy|IN JJS CD JJ NN|BODY_4|0
moves|NNS|BODY_11|0
the various states|DT JJ NNS|BODY_7|0
equation ( 11 )|NN -LRB- CD -RRB-|BODY_6|0
whole sequences|JJ NNS|BODY_4|0
one such sequence|CD JJ NN|BODY_1|0
an the process|DT DT NN|BODY_4|0
hampson [6|NN NNS|BODY_1|0
closer to 0|RBR TO CD|BODY_13|0
at least one i|IN JJS CD NN|BODY_14|0
i 0 vn (|FW CD NN -LRB-|BODY_4|0
( t )|-LRB- NN -RRB-|BODY_6|0
training backwards|NN NNS|BODY_3|0
td(-) and particularly td(0 )|JJ CC RB IN -RRB-|BODY_7|0
which action|WDT NN|BODY_5|0
' main motivations|POS JJ NNS|BODY_4|0
the true solution|DT JJ NN|BODY_9|0
the form|DT NN|BODY_10|0
the operation|DT NN|BODY_7|0
his system|PRP$ NN|BODY_6|0
some ffl|DT NN|BODY_5|0
w|NN|BODY_12|0
his proof|PRP$ NN|BODY_2|0
ji 2 ng|RB CD NN|BODY_18|0
showing convergence|VBG NN|BODY_4|0
[ q|NN NN|BODY_12|0
no error reduction|DT NN NN|BODY_2|0
the most inaccurate component|DT RBS JJ NN|BODY_6|0
state b|NN NN|BODY_2|0
the estimation system|DT NN NN|BODY_1|0
werbos [20] and sutton ( personal communication|NNS NN CC NN -LRB- JJ NN|BODY_1|0
all the others|PDT DT NNS|BODY_7|0
the td(-) procedure|DT JJ NN|BODY_22|0
the lower|DT JJR|BODY_1|0
-,|NN|BODY_3|0
absorbing states|JJ NNS|BODY_20|0
some state|DT NN|BODY_2|0
g.|NNP|BODY_5|0
general myampersandlambda|JJ NN|TITLE_4|0
further references|JJ NNS|BODY_2|0
this simpler category|DT JJR NN|BODY_7|0
this process|DT NN|BODY_1|0
the appropriate formula|DT JJ NN|BODY_1|0
the future|DT NN|ABSTRACT_6|0
this representation|DT NN|BODY_1|0
n b)g|NN NN|BODY_9|0
0 such that|CD JJ IN|BODY_1|0
the engineering method|DT NN NN|BODY_1|0
the quadratic form e e|DT JJ NN NN NN|BODY_1|0
the augmented term|DT JJ NN|BODY_8|0
comparing equations|VBG NNS|BODY_1|0
' vn ( i )|POS NN -LRB- IN -RRB-|BODY_14|0
representing v|VBG FW|BODY_1|0
a temporal difference method|DT JJ NN NN|BODY_7|0
the null subspace|DT JJ NN|BODY_9|0
early qn values|JJ NN NNS|BODY_15|0
every observation|DT NN|BODY_5|0
equation ( 7 )|NN -LRB- CD -RRB-|BODY_3|0
greater bias|JJR NN|BODY_3|0
lower bias|JJR NN|BODY_3|0
terminal absorbing values|NN JJ NNS|BODY_8|0
non-independent x i|JJ NN NN|BODY_7|0
these estimators|DT NNS|BODY_13|0
either y or z.|DT NN CC NN|BODY_9|0
the next stage|DT JJ NN|BODY_1|0
all other states|DT JJ NNS|BODY_11|0
an agent|DT NN|BODY_1|0
the absorbing states|DT JJ NNS|BODY_11|0
the q value|DT JJ NN|BODY_1|0
the theory|DT NN|BODY_1|0
a 2 a.|DT CD NN|BODY_8|0
such systems|JJ NNS|BODY_1|0
i 6= j|DT JJ NN|BODY_1|0
equation ( 1 )|NN -LRB- CD -RRB-|BODY_1|0
many other proposals|JJ JJ NNS|BODY_1|0
positive diagonal entries|JJ JJ NNS|BODY_7|0
completeness|NN|BODY_1|0
unhelpful state representations|JJ NN NNS|BODY_9|0
the kronecker delta|DT NN NN|BODY_30|0
( 3 )|-LRB- CD -RRB-|BODY_1|0
0 weights|CD NNS|BODY_8|0
a controlled , discounted , non-absorbing markov-process|DT VBN , VBN , JJ NN|BODY_1|0
a simple version|DT JJ NN|BODY_1|0
barto , sutton and anderson [2|NN , NN CC NN NNS|BODY_1|0
introduction many systems|NN JJ NNS|BODY_1|0
one action|CD NN|BODY_1|0
the random variables vn|DT JJ NNS NN|BODY_1|0
first sight|JJ NN|BODY_1|0
equation ( 21 )|NN -LRB- CD -RRB-|BODY_4|0
a or the right absorbing barrier|DT CC DT RB NN NN|BODY_7|0
appendix existence|VB NN|BODY_1|0
error|NN|BODY_4|0
the least mean squares algorithm|DT JJS JJ NNS NN|ABSTRACT_20|0
2.1|CD|BODY_1|0
its workings|PRP$ NNS|BODY_6|0
the initial predictor vn|DT JJ NN NN|BODY_5|0
vn+1 ( i 1 vn ( i 1 ff [vn|CD -LRB- FW CD NN -LRB- FW CD JJ NN|BODY_1|0
\gamma q|NN NN|BODY_3|0
the higher|DT JJR|BODY_1|0
weights|NNS|BODY_1|0
0 and 1 respectively|CD CC CD RB|BODY_22|0
3 states|CD NNS|BODY_1|0
2.2 localist representation equation|CD JJ NN NN|BODY_1|0
t :w|NN NN|BODY_11|0
some initial states|DT JJ NNS|BODY_1|0
' representation|POS NN|BODY_7|0
this proof|DT NN|BODY_1|0
the real terminal value z|DT JJ NN NN FW|BODY_10|0
the same representation|DT JJ NN|BODY_11|0
the sum converges|DT NN NNS|BODY_1|0
the actual td(-) algorithm|DT JJ JJ NN|BODY_1|0
the least means squares algorithm|DT JJS VBZ NNS NN|BODY_6|0
the condition|DT NN|BODY_1|0
that h|DT NN|BODY_1|0
the other states|DT JJ NNS|BODY_9|0
z n|FW NN|BODY_12|0
index t|NN NN|BODY_1|0
their scalar terminal value z|PRP$ NN NN NN FW|BODY_4|0
its path|PRP$ NN|BODY_5|0
the first|DT JJ|BODY_2|0
some point|DT NN|BODY_11|0
its associated contraction mappings|PRP$ JJ NN NNS|BODY_6|0
u|PRP|BODY_1|0
the methods|DT NNS|BODY_1|0
need|NN|BODY_1|0
' grid task|POS NN NN|BODY_12|0
the ff n|DT NN NN|BODY_1|0
that case|DT NN|BODY_1|0
the result|DT NN|BODY_3|0
its states and terminal values|PRP$ NNS CC NN NNS|BODY_3|0
this learning|DT NN|BODY_1|0
r further steps|NN JJ NNS|BODY_18|0
the positive ae.|DT JJ NN|BODY_6|0
the point|DT NN|BODY_1|0
uncoupled or disembodied moves|JJ CC JJ NNS|BODY_6|0
2.3 contraction mappings|CD NN NNS|BODY_1|0
a simpler alternative|DT JJR NN|BODY_1|0
a characteristic function|DT JJ NN|BODY_1|0
the basic algorithm|DT JJ NN|BODY_1|0
@ @w e e e|DT JJ NN NN NN|BODY_1|0
2.6 non-independence|CD NN|BODY_1|0
a td method|DT JJ NN|BODY_5|0
j 2 n|NN CD NN|BODY_12|0
just one state|RB CD NN|BODY_8|0
note|NN|BODY_1|0
3=4|CD|BODY_6|0
the same effect|DT JJ NN|BODY_7|0
the next which|DT JJ WDT|BODY_7|0
subsection 2.5|NN CD|BODY_5|0
his theorem|PRP$ NN|BODY_1|0
some parametric way|DT JJ NN|BODY_1|0
general|JJ|BODY_16|0
the discounting parameter|DT VBG NN|BODY_1|0
this combination estimator|DT NN NN|BODY_3|0
conclusions|NNS|BODY_1|0
experience|NN|BODY_4|0
4 this|CD DT|BODY_1|0
swoop|NN|BODY_9|0
a slightly modified version|DT RB VBN NN|ABSTRACT_9|0
transitions|NNS|BODY_7|0
the actual value|DT JJ NN|BODY_12|0
the learning rate|DT NN NN|BODY_6|0
the next state or states|DT JJ NN CC NNS|BODY_10|0
2.5|CD|BODY_1|0
generalisation|NN|BODY_2|0
a 2 n|DT CD NN|BODY_20|0
this error|DT NN|BODY_5|0
4|CD|BODY_1|0
these trivially|DT RB|BODY_1|0
j s|RB VBZ|BODY_1|0
its structure|PRP$ NN|BODY_6|0
the following subsections|DT VBG NNS|BODY_1|0
time and choices|NN CC NNS|BODY_2|0
any non-zero member|DT JJ NN|BODY_1|0
the obvious incremental update rule|DT JJ JJ NN NN|BODY_1|0
training forwards|NN NNS|BODY_1|0
the r-step estimate|DT JJ NN|BODY_1|0
t+1|NNS|BODY_15|0
those states|DT NNS|BODY_10|0
positive diagonal elements|JJ JJ NNS|BODY_2|0
vn+1 (|CD -LRB-|BODY_1|0
all states|DT NNS|BODY_11|0
the set|DT NN|BODY_6|0
the symmetry|DT NN|BODY_14|0
his analogue|PRP$ NN|BODY_1|0
a current location|DT JJ NN|BODY_9|0
the appropriate manner|DT JJ NN|BODY_6|0
the chain visits|DT NN NNS|BODY_6|0
the vectors x|DT NNS NN|BODY_1|0
the next section defines|DT JJ NN NNS|BODY_1|0
the information|DT NN|BODY_1|0
section 3|NN CD|BODY_1|0
many control problems|JJ NN NNS|BODY_1|0
=|SYM|BODY_18|0
an = a|DT SYM DT|BODY_9|0
policy|NN|BODY_9|0
d|NN|BODY_6|0
particular states|JJ NNS|BODY_10|0
this time|DT NN|BODY_13|0
time step r|NN NN NN|BODY_13|0
just individual ones|RB JJ NNS|BODY_6|0
an ffl|DT NN|BODY_20|0
clearly a td procedure|RB DT JJ NN|BODY_1|0
9ffl|NNP|BODY_5|0
discounted problems|VBD NNS|BODY_1|0
only r steps|RB JJ NNS|BODY_5|0
the introduction|DT NN|BODY_1|0
the original representation|DT JJ NN|BODY_6|0
their current states|PRP$ JJ NNS|BODY_5|0
the whole sequence|DT JJ NN|BODY_1|0
